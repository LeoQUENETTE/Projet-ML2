{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoQUENETTE/Projet-ML2/blob/textes/classif_textes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation collab"
      ],
      "metadata": {
        "id": "rLQnN5VY2lhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "3aw3KQ1w13bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "my_local_drive='/content/gdrive/My Drive/Colab Notebooks/ML_FDS'\n",
        "sys.path.append(my_local_drive)"
      ],
      "metadata": {
        "id": "clRWqfTU2rjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $my_local_drive"
      ],
      "metadata": {
        "id": "xdXOAyTz2tsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librairies"
      ],
      "metadata": {
        "id": "sa4k1ofx2v-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import zipfile\n",
        "import requests\n",
        "import io\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.utils import register_keras_serializable\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.metrics import Mean\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Pour utiliser au mieux le GPU\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "30-x3ZEG2076"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Récupération du jeu de données"
      ],
      "metadata": {
        "id": "ocJnxM_h23XL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.lirmm.fr/~poncelet/Ressources/flickr_subset2.zip\"\n",
        "target_dir = \"flickr_subset2\"\n",
        "\n",
        "# Vérifie si le dossier existe déjà\n",
        "if os.path.exists(target_dir) and os.path.isdir(target_dir):\n",
        "    print(\"Données déjà disponibles dans :\", target_dir)\n",
        "else:\n",
        "    print(\"Téléchargement de flickr_subset2.zip...\")\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        print(\"Téléchargement réussi. Extraction...\")\n",
        "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
        "            # Extraire sans ajouter de sous-dossier supplémentaire\n",
        "            for member in zip_ref.namelist():\n",
        "                # Corrige les chemins pour ignorer un éventuel prefixe flickr_subset2/\n",
        "                member_path = member\n",
        "                if member.startswith(\"flickr_subset2/\"):\n",
        "                    member_path = member[len(\"flickr_subset2/\"):]\n",
        "                target_path = os.path.join(target_dir, member_path)\n",
        "\n",
        "                # Si c'est un répertoire, on le crée\n",
        "                if member.endswith(\"/\"):\n",
        "                    os.makedirs(target_path, exist_ok=True)\n",
        "                else:\n",
        "                    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
        "                    with zip_ref.open(member) as source, open(target_path, \"wb\") as target:\n",
        "                        target.write(source.read())\n",
        "        print(f\"Données extraites dans : {target_dir}\")\n",
        "    else:\n",
        "        print(\"Échec du téléchargement. Code HTTP :\", response.status_code)"
      ],
      "metadata": {
        "id": "ZRtPxn_O27GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonctions, classes et variables utiles pour la suite"
      ],
      "metadata": {
        "id": "HKTenv-e2-xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FONCTIONS UTILES\n",
        "\n",
        "def preview_images_from_dir(image_dir, image_size=(224, 224), n=12,\n",
        "                            subset=\"training\", seed=123):\n",
        "    \"\"\"\n",
        "    Affiche n images avec leurs labels à partir d'un dossier\n",
        "    (flow_from_directory).\n",
        "    N'utilise PAS train_gen pour ne pas en avancer l'index.\n",
        "    \"\"\"\n",
        "    # Générateur léger juste pour l'aperçu\n",
        "    # Ici il y a une bonne indication si vous regardez bien pour la classif :)\n",
        "    preview_datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
        "\n",
        "    preview_gen = preview_datagen.flow_from_directory(\n",
        "        image_dir,\n",
        "        target_size=image_size,\n",
        "        batch_size=n,\n",
        "        class_mode=\"categorical\",\n",
        "        subset=subset,\n",
        "        shuffle=True,\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "    imgs, y = next(preview_gen)    # imgs: (n, H, W, 3), y: one-hot\n",
        "    class_names = list(preview_gen.class_indices.keys())\n",
        "    labels = np.argmax(y, axis=1)\n",
        "\n",
        "    rows = 3\n",
        "    cols = int(np.ceil(n / rows))\n",
        "    plt.figure(figsize=(4*cols, 4*rows))\n",
        "    for i in range(min(n, imgs.shape[0])):\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(imgs[i])\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_ZkJ5wPx3Bkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes à utiliser pour la partie classification de texte. Laquelle ?\n",
        "@register_keras_serializable()\n",
        "class SelectFirstToken (layers.Layer):\n",
        "  # Retourne le premier mot\n",
        "    def call(self, inputs):\n",
        "        return inputs[:, 0] # (batch, embed_dim)\n",
        "\n",
        "@register_keras_serializable()\n",
        "class SelectMean(layers.Layer):\n",
        "  # Retourne la moyenne des mots - bien si pas trop de PAD - chaînes même taille\n",
        "    def call(self, inputs):\n",
        "        # inputs: (batch, seq_len, embed_dim)\n",
        "        return tf.reduce_mean(inputs, axis=1)  # (batch, embed_dim)\n",
        "\n",
        "\n",
        "@register_keras_serializable()\n",
        "class MaskedMean(layers.Layer):\n",
        "  # Retourne la moyenne des mots sans être trop influencé par PAD\n",
        "    def call(self, inputs):\n",
        "        seq_out, token_ids = inputs   # (B,L,D), (B,L)\n",
        "        mask = tf.cast(tf.not_equal(token_ids, 0), seq_out.dtype)  # PAD=0\n",
        "        mask = tf.expand_dims(mask, -1)        # (B,L,1)\n",
        "        summed = tf.reduce_sum(seq_out * mask, axis=1)             # (B,D)\n",
        "        counts = tf.reduce_sum(mask, axis=1)                        # (B,1)\n",
        "        return summed / tf.maximum(counts, 1.0)\n",
        "\n",
        "\n",
        "# Classe utile pour la partie Clip mais il fallait bien regarder pour la trouver\n",
        "@register_keras_serializable()\n",
        "class L2Normalize(layers.Layer):\n",
        "    def __init__(self, axis=-1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.math.l2_normalize(inputs, axis=self.axis)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"axis\": self.axis})\n",
        "        return config\n",
        "\n",
        "# PARTIE SMALL_BERT = COPIE DU NOTEBOOK\n",
        "# ============================\n",
        "# PositionalEmbedding Layer\n",
        "# ============================\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(input_dim=vocab_size,\n",
        "                                                 output_dim=embed_dim)\n",
        "        self.position_embeddings = layers.Embedding(input_dim=sequence_length,\n",
        "                                                    output_dim=embed_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(0, length)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "# ============================\n",
        "# TransformerBlock\n",
        "# ============================\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads,ff_dim, dropout_rate=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads,\n",
        "                                             key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training=False, mask=None):\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "        attn_mask = None\n",
        "        if mask is not None:\n",
        "            attn_mask = tf.cast(mask[:, tf.newaxis, :], dtype=tf.float32)\n",
        "            attn_mask = tf.tile(attn_mask, [1, seq_len, 1])\n",
        "\n",
        "        attn_output = self.att(inputs, inputs, inputs, attention_mask=attn_mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        def get_config(self):\n",
        "            config = super().get_config()\n",
        "            config.update({\n",
        "                \"embed_dim\": self.att.key_dim,\n",
        "                \"num_heads\": self.att.num_heads,\n",
        "                \"ff_dim\": self.ffn.layers[0].units,\n",
        "                \"dropout_rate\": self.dropout1.rate,\n",
        "            })\n",
        "            return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "# ============================\n",
        "# SmallBERT encoder\n",
        "# ============================\n",
        "@register_keras_serializable()\n",
        "class SmallBERT(tf.keras.Model):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, num_heads,\n",
        "                 ff_dim, num_layers, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(sequence_length, vocab_size,\n",
        "                                                 embed_dim)\n",
        "\n",
        "        self.transformer_blocks = [\n",
        "            TransformerBlock(embed_dim,\n",
        "                             num_heads, ff_dim) for _ in range(num_layers)\n",
        "        ]\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.pos_embedding(inputs)\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x, training=training)\n",
        "        x = self.layernorm(x)\n",
        "        return self.dropout(x, training=training)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"ff_dim\": self.ff_dim,\n",
        "            \"num_layers\": self.num_layers,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n"
      ],
      "metadata": {
        "id": "GRR3Hiui3Ec3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Répertoire cible pour sauvegarder vos modèles\n",
        "model_dir = \"./models_forclip\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Répertoire des données\n",
        "dataset_dir = \"./flickr_subset2\"\n",
        "\n",
        "# Répertoire des images\n",
        "image_dir = os.path.join(dataset_dir, \"images\")\n",
        "# Répertoire des captions\n",
        "captions_dir = os.path.join(dataset_dir, \"captions\")\n",
        "\n",
        "# Variables utiles\n",
        "# Attention respecter bien l'ordre alphabétique des classes pour\n",
        "# le générateur\n",
        "class_names = ['ball', 'bike', 'dog', 'water']\n",
        "# Pour les images\n",
        "image_size=(224, 224)\n",
        "image_shape = image_size + (3,)\n",
        "\n",
        "# Pour les textes\n",
        "sequence_length = 32\n",
        "vocab_size = 10000\n",
        "num_heads = 4\n",
        "ff_dim = 256\n",
        "num_layers = 2\n",
        "\n",
        "# Pour les images et les textes dans le modèle CLIP\n",
        "embed_dim = 128"
      ],
      "metadata": {
        "id": "FyZ__Dg-3Kbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie classification de textes"
      ],
      "metadata": {
        "id": "QUl6l30A3IF4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hQzFCnuc3PPo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}